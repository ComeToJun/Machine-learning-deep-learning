{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20201008 딥러닝 4",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "60e3bafaae42476986f2da25eddda5d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9317fa69d36c46f58b41458c2c08ba00",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a6979b7304984281bb519a60277f0633",
              "IPY_MODEL_38a931fb405e4c66bdbd87ca8dca4873"
            ]
          }
        },
        "9317fa69d36c46f58b41458c2c08ba00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a6979b7304984281bb519a60277f0633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4767a7b7cddc4ff2a2c9a005baa08a46",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 100000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b6fa2951f2c4564b07d1b4ea22c87e0"
          }
        },
        "38a931fb405e4c66bdbd87ca8dca4873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2c3fec6c69ec45e2873136e3caeefa3d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10/100000 [11:21&lt;1808:36:46, 65.12s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5eecef73b4840fdb485e1d47d5c9cf0"
          }
        },
        "4767a7b7cddc4ff2a2c9a005baa08a46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b6fa2951f2c4564b07d1b4ea22c87e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c3fec6c69ec45e2873136e3caeefa3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5eecef73b4840fdb485e1d47d5c9cf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgFTvEBjfzbI"
      },
      "source": [
        "## 경사하강법\n",
        "\n",
        "* 최적의 매개변수 값을 찾는 것\n",
        "* 오차를 적게 하는 매개변수를 찾는 것\n",
        "* 경사하강법 식은 fit 할때 생김\n",
        "* 출력층에서 계산된다고 생각하면 됨\n",
        "\n",
        "## 신경망의 목적은 오차를 최소화할 수 있는 가중치(W)와 편향(B)을 구하는 것\n",
        "* 오차를 구하기 위해서는 예측값이 필요\n",
        "* 예측값을 통해 오차를 구할 수 있음\n",
        "* 방향은 미분에 의해서 결정되고, 얼만큼 갈지에 대한 것은 [에타]러닝 레이트( 하이퍼 파라미터 ) 에 의해 결정진다 ( 일반적으로 0.01 정도로 움직인다 )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRRzyOQdqlFp"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 미분코드\n",
        "\n",
        "def _numerical_gradient_no_batch(f, x):\n",
        "    h = 1e-4 # 0.0001\n",
        "    grad = np.zeros_like(x) # x와 형상이 같은 배열을 생성\n",
        "    for idx in range(x.size):\n",
        "        tmp_val = x[idx]\n",
        "        # f(x+h) 계산\n",
        "        x[idx] = float(tmp_val) + h\n",
        "        fxh1 = f(x)\n",
        "        # f(x-h) 계산\n",
        "        x[idx] = tmp_val - h \n",
        "        fxh2 = f(x) \n",
        "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "        x[idx] = tmp_val # 값 복원\n",
        "    return grad\n",
        "    \n",
        "\n",
        "# 배치미분을 사용해서 여러개를 한번에 작업 할 수 있게 한다. \n",
        "# 여러개를 한다는 의미는 편미분을 한다고도 볼 수 있다.\n",
        "\n",
        "def numerical_gradient(f, X):\n",
        "    if X.ndim == 1:\n",
        "        return _numerical_gradient_no_batch(f, X)\n",
        "    else:\n",
        "        grad = np.zeros_like(X)\n",
        "        for idx, x in enumerate(X):\n",
        "            grad[idx] = _numerical_gradient_no_batch(f, x)\n",
        "        return grad"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g3L29PZhA10"
      },
      "source": [
        "# f : 비용함수 또는 손실함수 ( Cost Function, Loss Function)\n",
        "# init_x : 초기값\n",
        "# lr : 학습률\n",
        "# step_num : 갱신할 횟수 ( 미분 횟수 )\n",
        "# 경사하강법 공식\n",
        "\n",
        "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
        "  x = init_x\n",
        "\n",
        "  for i in range(step_num):\n",
        "    grad = numerical_gradient(f, x)\n",
        "    x -= lr * grad\n",
        "  return x"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gYZw9_oqenm",
        "outputId": "eec2d4bd-7cdc-4aeb-bb4d-26d4d90afad6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# x[0] = -3.0, x[1] = 4.0\n",
        " \n",
        "def function_2(x):\n",
        "    return x[0]**2 + x[1]**2\n",
        "\n",
        "init_x = np.array([-3.0, 4.0])\n",
        "gradient_descent(function_2, init_x, lr=0.1, step_num=100)\n",
        "\n",
        "# function_2 에 대한 최소값"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-6.11110793e-10,  8.14814391e-10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oDHZh5nqe_L",
        "outputId": "7b0f8b48-e833-4f63-a929-c3917fb35fec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# coding: utf-8\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "\n",
        "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
        "    x = init_x\n",
        "    x_history = []\n",
        "\n",
        "    for i in range(step_num):\n",
        "        x_history.append( x.copy() )  # <- 이것만 바뀜\n",
        "\n",
        "        grad = numerical_gradient(f, x)\n",
        "        x -= lr * grad\n",
        "\n",
        "    return x, np.array(x_history)\n",
        "\n",
        "init_x = np.array([-3.0, 4.0])    \n",
        "\n",
        "lr = 0.1\n",
        "step_num = 20\n",
        "x, x_history = gradient_descent(function_2, init_x, lr=lr, step_num=step_num)\n",
        "\n",
        "plt.plot( [-5, 5], [0,0], '--b')\n",
        "plt.plot( [0,0], [-5, 5], '--b')\n",
        "plt.plot(x_history[:,0], x_history[:,1], 'o')\n",
        "\n",
        "plt.xlim(-3.5, 3.5)\n",
        "plt.ylim(-4.5, 4.5)\n",
        "plt.xlabel(\"X0\")\n",
        "plt.ylabel(\"X1\")\n",
        "plt.show()"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uJ6mhYCxgYG",
        "outputId": "d09bdd27-084a-439e-d676-f43112c32416",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 학습률이 너무 큰 예. lr = 10.0\n",
        "init_x = np.array([-3.0, 4.0])\n",
        "result, _ = gradient_descent(function_2, init_x=init_x, lr=10.0, step_num=100)\n",
        "print(\"Learning Rate 10.0 : {}\".format(result))\n",
        "\n",
        "\n",
        "# 학습률이 너무 작은 예. lr = 1e-10\n",
        "init_x = np.array([-3.0, 4.0])\n",
        "result, _ = gradient_descent(function_2, init_x=init_x, lr=1e-10, step_num=100)\n",
        "print(\"Learning Rate 1e-10 : {}\".format(result))"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning Rate 10.0 : [-2.58983747e+13 -1.29524862e+12]\n",
            "Learning Rate 1e-10 : [-2.99999994  3.99999992]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUEl0GJHxybc",
        "outputId": "f0a4829f-5496-472d-8c5b-820badb2591b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd common/\n",
        "!unzip common.zip"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'common/'\n",
            "/content/common\n",
            "Archive:  common.zip\n",
            "replace functions.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5BGEsHB2PgF"
      },
      "source": [
        "import sys, os\n",
        "sys.path.append(os.pardir)\n",
        "from common.functions import softmax, cross_entropy_error\n",
        "from common.gradient import numerical_gradient\n",
        "\n",
        "class SimpleNet:\n",
        "  # 가중치와 편향을 미리 만들어두어야 한다.\n",
        "  \n",
        "  def __init__(self):\n",
        "    self.W = np.random.randn(2, 3) # 2 x 3 형태로 정규분포로 이루어진 가중치의 초기값 생성\n",
        "\n",
        "  def predict(self, x):\n",
        "    return np.dot(x, self.W) # 입력값과 가중치의 내적을 return\n",
        "\n",
        "  def loss(self, x, t):\n",
        "    z = self.predict(x)\n",
        "    y = softmax(z)\n",
        "    loss = cross_entropy_error(y, t)\n",
        "\n",
        "    return loss\n"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJdt_5vg3Inu",
        "outputId": "006cfd61-0c14-4da9-c5c0-dc37122e7648",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "net = SimpleNet()\n",
        "net.W"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.43577756,  2.13201476,  1.13767521],\n",
              "       [ 1.74076816,  1.02548652, -1.22860829]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb170yfC5Yr8"
      },
      "source": [
        "x = np.array([0.6, 0.9])\n",
        "p = net.predict(x)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJulvIeq8qgu",
        "outputId": "10246c28-0675-44e3-adf6-4523a60303ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "p"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.82815789,  2.20214673, -0.42314233])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9WYXeks8qvy",
        "outputId": "4753294b-e2f6-4c84-8393-5316d1a248bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.argmax(p)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XILvsCAd8vfa",
        "outputId": "acdcce51-4838-450b-82fc-ab39c19a0a0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t = np.array([0, 1, 0]) # 원 핫 인코딩 되어있음\n",
        "net.loss(x, t)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5655428159014214"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPxaHvae9Uyq",
        "outputId": "f4c0d144-e4b4-443a-d1b3-74e321559941",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def f(w):\n",
        "  return net.loss(x, t)  # loss 안에 있는 x t 가 미분을 해야하는 대상이 된다.\n",
        "\n",
        "dW = numerical_gradient(f, net.W) # 기울기의 벡터를 구하는 것\n",
        "dW\n",
        "\n",
        "# 절대값으로 이해해서 -와 + 상관없이 값의 차이가 가장 큰 W 가 loss 에 가장 영향을 준다.\n",
        "# 변화량이 가장 큰 것은 5번째 W \n",
        "# 결국 0에 최대한 가까이 가는게 목적이기 때문에 그 차가 가장 큰 것이 변화량이 크고, loss 에 영향을 많이 주는 것."
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.23448641, -0.25916899,  0.02468257],\n",
              "       [ 0.35172962, -0.38875348,  0.03702386]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmsSGjKr-BEr"
      },
      "source": [
        "## MNIST 데이터셋 분류 신경망 만들기\n",
        "\n",
        "# 변수\n",
        "\n",
        "params : 신경망의 매개변수를 보관합니다.\n",
        "\n",
        "params['W1']은 1번째 층의 가중치, \n",
        "\n",
        "params['b1']은 1번째 층의 편향\n",
        "\n",
        "params['W2']는 2번째 층의 가중치, \n",
        "\n",
        "params['b2']도 2번째 층의 편향\n",
        "\n",
        "grads : 각 매개변수의 기울기를 보관합니다.\n",
        "\n",
        "grads['W1']은 1번째 층의 가중치의 기울기,\n",
        "\n",
        "grads['b1']은 1번째 층의 편향의 기울기\n",
        "\n",
        "grads['W2']은 2번째 층의 가중치의 기울기, \n",
        "\n",
        "grads['b2']은 2번째 층의 편향의 기울기\n",
        "\n",
        "\n",
        "# 메소드\n",
        "\n",
        "init : 초기화 작업을 수행합니다.\n",
        "\n",
        "input_size : 입력층의 뉴런 수\n",
        "\n",
        "hidden_size : 은닉층의 뉴런 수\n",
        "\n",
        "output_size : 출력층의 뉴런 수\n",
        "\n",
        "weight_init_std : 생성되는 가중치가 정규분포를 가지기 위한 상숫값\n",
        "\n",
        "predict : 예측(추론)을 수행합니다.\n",
        "\n",
        "x : 이미지 데이터\n",
        "\n",
        "loss : 손실 함수의 값을 구합니다.\n",
        "\n",
        "x : 이미지 데이터\n",
        "\n",
        "t : 정답 레이블\n",
        "\n",
        "accuracy : 정확도를 구합니다. 매개변수는 loss와 같습니다.\n",
        "\n",
        "numerical_gradient : 가중치 매개변수의 기울기를 구합니다. 매개변수는 loss와 같습니다.\n",
        "\n",
        "gradient : numerical_gradient의 개선판 입니다.\n",
        "\n",
        "오차역전파법을 배우고 나서 구현할 예정입니다. \n",
        "매개변수는 loss와 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbO8ecTSBRFb"
      },
      "source": [
        "from common.functions import *\n",
        "from common.gradient import numerical_gradient\n",
        "\n",
        "class TwoLayerNet:\n",
        "\n",
        "  # 신경망 초기화\n",
        "  def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
        "    # 사용할 매개변수를 준비 ( 매개변수에 대한 초기 설정 )\n",
        "    # 가중치는 정규분포로 이루어진 랜덤값을 사용\n",
        "    # 편향은 0으로 초기화 하는 것이 일반적\n",
        "\n",
        "    # 가중치를 담아놓을 딕셔너리\n",
        "    self.params = {}\n",
        "\n",
        "    # 1층 ( 은닉층 ) 의 매개변수 설정\n",
        "    self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size) # 784개의 입력을 받는 100개의 뉴런 생성\n",
        "    self.params['b1'] = np.zeros(hidden_size)\n",
        "\n",
        "    # 2층 ( 출력층 ) 매개변수 설정\n",
        "    self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) # 100개의 입력을 받는 10개의 뉴런\n",
        "    self.params['b2'] = np.zeros(output_size)\n",
        "    \n",
        "  # 예측 ( 소프트 맥스를 사용할 예정)\n",
        "  def predict(self, x):\n",
        "    # 가중치, 편향 불러오기\n",
        "    W1, W2 = self.params['W1'], self.params['W2']\n",
        "    b1, b2 = self.params['b1'], self.params['b2']\n",
        "\n",
        "    # 1-1 1층의 내적 구하기 (Dense, Affine)\n",
        "    z1 = np.dot(x, W1) + b1\n",
        "    # 1-2 내적에 대한 활성화 함수 적용 (시그모이드)\n",
        "    a1= sigmoid(z1)\n",
        "\n",
        "    # 2-1 2층의 내적 구하기\n",
        "    z2 = np.dot(a1,W2) + b2\n",
        "    # 2-2 2층의 출력함수 적용하기 (소프트맥스)    \n",
        "    # 시그모이드 소프트맥스를 바로 사용할 수 있는 이유는 from common.functions import * 덕분\n",
        "    y = softmax(z2)\n",
        "    \n",
        "    return y\n",
        "\n",
        "  # 비용 함수\n",
        "  def loss(self, x, t):\n",
        "    pred = self.predict(x)\n",
        "    # 예측한 결과물, 정답에 대한 loss를 구하면 된다.\n",
        "    return cross_entropy_error(pred, t)\n",
        "\n",
        "  # 정확도 확인하기\n",
        "  def accuracy(self, x, t):\n",
        "    y = self.predict(x) # 소프트맥스의 결과\n",
        "    y = np.argmax(y, axis=1)  # axis=1 을 준 이유 : 각각의 행에서 인덱스를 추출 하기 위함\n",
        "    t = np.argmax(t, axis=1)\n",
        "\n",
        "    accuracy = np.sum(y == t) / float(x.shape[0]) # 데이터의 개수 60000개 \n",
        "    return accuracy\n",
        "\n",
        "  # TwolayerNet 의 미분 수행 함수\n",
        "  # x : 입력 데이터, t : 정답 레이블\n",
        "  def numerical_gradient(self, x, t):\n",
        "    loss_W = lambda W : self.loss(x, t)\n",
        "\n",
        "    # 각 층에서 구해지는 기울기를 저장할 딕셔너리\n",
        "    grads = {}\n",
        "\n",
        "    # 1층의 가중치들의 기울기를 구한다. ( LOSS에 대한 W1 의 기울기 )\n",
        "    grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "    grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "    \n",
        "    # 2층의 가중치들의 기울기를 구한다. ( LOSS에 대한 W2 의 기울기 )\n",
        "    grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "    grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "    \n",
        "    return grads\n"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZYsfpmda-bx",
        "outputId": "7b74e950-4929-4716-8cdd-675ec1e5db60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 신경망 생성하기\n",
        "input_size=28*28\n",
        "hidden_size=100\n",
        "output_size=10   # 숫자의 개수만큼\n",
        "\n",
        "\n",
        "net = TwoLayerNet(input_size=input_size, hidden_size=hidden_size, output_size=output_size)\n",
        "print(net.params['W1'].shape)\n",
        "print(net.params['b1'].shape)\n",
        "print(net.params['W2'].shape)\n",
        "print(net.params['b1'].shape)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784, 100)\n",
            "(100,)\n",
            "(100, 10)\n",
            "(100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cSis48ZbLJh",
        "outputId": "95ad4da7-48ff-4eba-c2fa-7f59a8f9b9c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "net.params['W1'].shape, net.params['W2'].shape"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((784, 100), (100, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H1LHHikc2AR"
      },
      "source": [
        "# 100개의 데이터를 임의로 준비\n",
        "x = np.random.rand(100, 784) # 100장의 미니배치\n",
        "y = net.predict(x)"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfOrZttidJcP",
        "outputId": "d7784a2d-2ed4-4f00-83df-3e825a20f251",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 예측이 잘된것을 확인할 수 있다\n",
        "x.shape, y.shape"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100, 784), (100, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHu37EYcqcT3"
      },
      "source": [
        "1. 변환기\n",
        " - 사이킷 런 변환기\n",
        " - 만들어보기\n",
        " - numpy\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiBEM4VQdOc4"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras import datasets\n",
        "mnist = datasets.mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXKP5Wrhfg6X"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "y_train_dummy = OneHotEncoder().fit_transform(y_train.reshape(-1,1))\n",
        "y_train_dummy = y_train_dummy.toarray()\n",
        "\n",
        "y_test_dummy = OneHotEncoder().fit_transform(y_test.reshape(-1,1))\n",
        "y_test_dummy = y_test_dummy.toarray()"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLu-CfFUht7T",
        "outputId": "2d402967-3cd6-4acf-acbc-93c1b822fb68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "X_train = X_train / 255.0\n",
        "X_train.shape"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMOuyAo9n_EJ",
        "outputId": "813feea3-caf5-40d8-d542-a61d957148eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "X_test = X_test / 255.0\n",
        "X_test.shape"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEv5tnF_tu3h"
      },
      "source": [
        "## 전처리 결과 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb8Ksovgt_hv",
        "outputId": "259e6d1d-8c50-44b8-f3ab-d8a3f491fcda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train.shape, y_train_dummy.shape"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (60000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ0I9p3wuCLH",
        "outputId": "40ec9f46-acc1-441b-9468-fe8b2a64ba24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_test.shape, y_test_dummy.shape"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 784), (10000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-KDlnT-uENH",
        "outputId": "e1148375-6175-4194-b83b-5926854bfe26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train_dummy[0]"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQXfikZiuFCg"
      },
      "source": [
        "## 훈련\n",
        "* 미니배치 선정\n",
        "* 반복 횟수 설정\n",
        "* 학습률 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqr-7chMu6iv",
        "outputId": "95320b1c-f795-4253-dd88-d8e2c141ad76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716,
          "referenced_widgets": [
            "60e3bafaae42476986f2da25eddda5d0",
            "9317fa69d36c46f58b41458c2c08ba00",
            "a6979b7304984281bb519a60277f0633",
            "38a931fb405e4c66bdbd87ca8dca4873",
            "4767a7b7cddc4ff2a2c9a005baa08a46",
            "7b6fa2951f2c4564b07d1b4ea22c87e0",
            "2c3fec6c69ec45e2873136e3caeefa3d",
            "b5eecef73b4840fdb485e1d47d5c9cf0"
          ]
        }
      },
      "source": [
        "from tqdm import tqdm_notebook\n",
        "\n",
        "iter_nums = 100000 # 반복 횟수\n",
        "train_size = X_train.shape[0]  # 배치를 만들기 위한 전체 데이터 개수\n",
        "batch_size = 100 # 배치 크기 설정, 600개의 배치가 생긴다.\n",
        "learning_rate = 0.1\n",
        "\n",
        "network = TwoLayerNet(input_size=28*28, hidden_size=50, output_size=10)\n",
        "\n",
        "for i in tqdm_notebook(range(iter_nums)):\n",
        "  # 미니배치 획득\n",
        "  batch_mask = np.random.choice(train_size, batch_size)\n",
        "\n",
        "  X_batch = X_train[batch_mask] # 랜덤하게 100개의 데이터를 추출해서 배치 데이터로 만들기\n",
        "  t_batch = y_train[batch_mask] # 랜덤하게 100개의 데이터를 추출해서 배치 데이터에 대한 정답 만들기\n",
        "\n",
        "  # 기울기 계산\n",
        "  # numerical_gradient 함수 내부에서 벌어지는 일\n",
        "  # 1. 예측\n",
        "  # 2. cross_entropy_error 를 통한 Loss 구하기\n",
        "  # 3. 구해진 Loss 값을 이용해 미분을 수행\n",
        "  grad = network.numerical_gradient(X_batch, t_batch)\n",
        "\n",
        "  # 매개변수 갱신 ( 경사 하강법 수행 )\n",
        "  for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "    network.params[key] -= learning_rate * grad[key]\n",
        "\n",
        "  # 학습 경과 기록\n",
        "  loss= network.loss(X_batch, t_batch)\n",
        "  print(\"Step {} => Loss : {}\".format(i, loss))\n",
        "  # train_loss_list.append(loss)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60e3bafaae42476986f2da25eddda5d0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Step 0 => Loss : 2.284893061495402\n",
            "Step 1 => Loss : 2.2983583150921674\n",
            "Step 2 => Loss : 2.2962229412802553\n",
            "Step 3 => Loss : 2.2846422052085504\n",
            "Step 4 => Loss : 2.28839549237259\n",
            "Step 5 => Loss : 2.28918992727196\n",
            "Step 6 => Loss : 2.2685409153819993\n",
            "Step 7 => Loss : 2.2841931043484283\n",
            "Step 8 => Loss : 2.3082334748031403\n",
            "Step 9 => Loss : 2.2926079652800277\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-170-bff5258937bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;31m# 2. cross_entropy_error 를 통한 Loss 구하기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;31m# 3. 구해진 Loss 값을 이용해 미분을 수행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;31m# 매개변수 갱신 ( 경사 하강법 수행 )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-149-3b1edf58321a>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# 1층의 가중치들의 기울기를 구한다. ( LOSS에 대한 W1 의 기울기 )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/common/gradient.py\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(f, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mtmp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mfxh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# f(x+h)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_val\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-149-3b1edf58321a>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0;31m# x : 입력 데이터, t : 정답 레이블\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mloss_W\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# 각 층에서 구해지는 기울기를 저장할 딕셔너리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-149-3b1edf58321a>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0;31m# 비용 함수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;31m# 예측한 결과물, 정답에 대한 loss를 구하면 된다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcross_entropy_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-149-3b1edf58321a>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# 1-1 1층의 내적 구하기 (Dense, Affine)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;31m# 1-2 내적에 대한 활성화 함수 적용 (시그모이드)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0ma1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCoWkc17zw2l",
        "outputId": "d3485fc6-6b6f-4581-a770-0e2ec98bd6de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        }
      },
      "source": [
        "network = TwoLayerNet(input_size=28*28, hidden_size=50, output_size=10)\n",
        "\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\n",
        "\n",
        "for i in range(iter_nums):\n",
        "  batch_mask = np.random.choice(train_size, batch_size)\n",
        "  X_batch = X_train[batch_mask]\n",
        "  t_batch = y_train[batch_mask]\n",
        "\n",
        "  grad = network.numerical_gradient(X_batch, t_batch)\n",
        "\n",
        "  for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "    network.params[key] -= learning_rate * grad[key]\n",
        "\n",
        "  loss = network.loss(X_batch, t_batch)\n",
        "  print(\"Loss: {}\".format(loss))\n",
        "\n",
        "  if i % iter_per_epoch == 0:\n",
        "    train_acc = network.accuracy(X_train, y_train_dummy)\n",
        "    test_acc = network.accuracy(X_test, y_test_dummy)\n",
        "    # train_acc_list.append(train_acc)\n",
        "    # test_acc_list.appedn(test_acc)\n",
        "\n",
        "    print(\"train acc : {}, /  test acc : {}\".format(train_acc, test_acc))"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 2.2915190271551107\n",
            "train acc : 0.0993, /  test acc : 0.1032\n",
            "Loss: 2.2913500887615554\n",
            "Loss: 2.29505094384488\n",
            "Loss: 2.29020930327256\n",
            "Loss: 2.299371666334739\n",
            "Loss: 2.2904381987335167\n",
            "Loss: 2.292763319663791\n",
            "Loss: 2.2942070290061904\n",
            "Loss: 2.28695286311015\n",
            "Loss: 2.2897990415517837\n",
            "Loss: 2.2936262112385317\n",
            "Loss: 2.2901042895340424\n",
            "Loss: 2.2936953698793814\n",
            "Loss: 2.299097176896642\n",
            "Loss: 2.293761072451909\n",
            "Loss: 2.295154744943696\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-180-78c62afe074b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mt_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'W2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-179-7b4fdc8db2b5>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# 1층의 가중치들의 기울기를 구한다. ( LOSS에 대한 W1 의 기울기 )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/common/gradient.py\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(f, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_val\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mfxh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# f(x-h)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfxh1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfxh2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-179-7b4fdc8db2b5>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0;31m# x : 입력 데이터, t : 정답 레이블\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mloss_W\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# 각 층에서 구해지는 기울기를 저장할 딕셔너리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-179-7b4fdc8db2b5>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0;31m# 비용 함수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;31m# 예측한 결과물, 정답에 대한 loss를 구하면 된다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcross_entropy_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-179-7b4fdc8db2b5>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# 1-1 1층의 내적 구하기 (Dense, Affine)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;31m# 1-2 내적에 대한 활성화 함수 적용 (시그모이드)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0ma1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcG87oWlzyUR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}